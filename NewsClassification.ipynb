{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec734b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlehub -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d28304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddlehub as hub\n",
    "import paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fdf8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看Paddle、PaddleHub版本以及模型信息\n",
    "print(paddle.__version__)\n",
    "!pip show paddlehub\n",
    "\n",
    "model = hub.Module(name=\"ernie\", task='seq-cls', num_classes=14) # 在多分类任务中，num_classes需要显式地指定类别数，此处根据数据集设置为14\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment.\n",
    "%cd ./data/data16287/\n",
    "!tar -zxvf thu_news.tar.gz\n",
    "!ls -hl thu_news\n",
    "\n",
    "print(\"题目二：打印验证集前3条数据\")\n",
    "!head -n 4 thu_news/valid.txt\n",
    "print(\"题目二：打印验证集后3条数据\")\n",
    "!tail -n 3 thu_news/valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312bccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, csv\n",
    "from paddlehub.datasets.base_nlp_dataset import InputExample, TextClassificationDataset\n",
    "\n",
    "# 数据集存放位置\n",
    "DATA_DIR=\"./data/data16287/thu_news\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThuNews(TextClassificationDataset):\n",
    "    def __init__(self, tokenizer, mode='train', max_seq_len=128):\n",
    "        if mode == 'train':\n",
    "            data_file = 'train.txt'\n",
    "        elif mode == 'test':\n",
    "            data_file = 'test.txt'\n",
    "        else:\n",
    "            data_file = 'valid.txt'\n",
    "        super(ThuNews, self).__init__(\n",
    "            base_path=DATA_DIR,\n",
    "            data_file=data_file,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_len=max_seq_len,\n",
    "            mode=mode,\n",
    "            is_file_with_header=True,\n",
    "            label_list=['体育', '科技', '社会', '娱乐', '股票', '房产', '教育', '时政', '财经', '星座', '游戏', '家居', '彩票', '时尚'])\n",
    "\n",
    "    # 解析文本文件里的样本\n",
    "    def _read_file(self, input_file, is_file_with_header: bool = False):\n",
    "        if not os.path.exists(input_file):\n",
    "            raise RuntimeError(\"The file {} is not found.\".format(input_file))\n",
    "        else:\n",
    "            with io.open(input_file, \"r\", encoding=\"UTF-8\") as f:\n",
    "                reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)\n",
    "                examples = []\n",
    "                seq_id = 0\n",
    "                header = next(reader) if is_file_with_header else None\n",
    "                for line in reader:\n",
    "                    example = InputExample(guid=seq_id, text_a=line[0], label=line[1])\n",
    "                    seq_id += 1\n",
    "                    examples.append(example)\n",
    "                return examples\n",
    "\n",
    "train_dataset = ThuNews(model.get_tokenizer(), mode='train', max_seq_len=128)\n",
    "dev_dataset = ThuNews(model.get_tokenizer(), mode='dev', max_seq_len=128)\n",
    "test_dataset = ThuNews(model.get_tokenizer(), mode='test', max_seq_len=128)\n",
    "for e in train_dataset.examples[:3]:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = paddle.optimizer.Adam(learning_rate=5e-5, parameters=model.parameters())  # 优化器的选择和参数配置\n",
    "trainer = hub.Trainer(model, optimizer, checkpoint_dir='./ckpt', use_gpu=True)        # fine-tune任务的执行者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b9061",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(train_dataset, epochs=3, batch_size=32, eval_dataset=dev_dataset, save_interval=1)   # 配置训练参数，启动训练，并指定验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35769795",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.evaluate(test_dataset, batch_size=32)    # 在测试集上评估当前训练模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
